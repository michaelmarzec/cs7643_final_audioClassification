{"cells":[{"cell_type":"markdown","id":"0eca8791","metadata":{"id":"0eca8791"},"source":["# CS7643 Final Project\n","\n","This notebook is meant to go through the different models and experiment on our dataset containing 21782 training samples on different sounds. \n","\n","## Group Members\n","Zach Halaby\n","Michael Marzec\n","Shayan Mukhtar\n","\n","## Dataset\n","\n","The dataset was obtained under Google's GPL license terms from the following site: https://research.google.com/audioset/download.html"]},{"cell_type":"markdown","id":"ImJTVnHG3Pm8","metadata":{"id":"ImJTVnHG3Pm8"},"source":["## Colab Prep"]},{"cell_type":"markdown","id":"bLriXwfJ3zCv","metadata":{"id":"bLriXwfJ3zCv"},"source":["github <--> colab instructions: https://medium.com/analytics-vidhya/how-to-use-google-colab-with-github-via-google-drive-68efb23a42d"]},{"cell_type":"code","execution_count":null,"id":"FBltGWVZ2isD","metadata":{"id":"FBltGWVZ2isD"},"outputs":[],"source":["### If using Google Colab\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"a58fdnJQ10uF","metadata":{"id":"a58fdnJQ10uF"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","id":"f3qpir-v4wqB","metadata":{"id":"f3qpir-v4wqB"},"source":["### Initial Cloning"]},{"cell_type":"code","execution_count":null,"id":"eHOQoJtl4wRe","metadata":{"id":"eHOQoJtl4wRe"},"outputs":[],"source":["### cd to github drive (create the folder, if it doesn't already exist)\n","%cd /content/drive/Othercomputers/My\\ MacBook\\ Pro\\ \\(1\\)\n","\n","# git clone -b branch https://{git_token}@github.com/{username}/{repository}\n","# See instructions file if you're unfamiliar with generating git_tokens\n","\n","username = 'shayanmukhtar'\n","repository = 'cs7643_final'\n","# git_token = \n","\n","# !git clone -b UPDATE_BRANCH https://{git_token}@github.com/{username}/{repository}\n","\n"]},{"cell_type":"markdown","id":"6dk6W6qg6oF6","metadata":{"id":"6dk6W6qg6oF6"},"source":["### Git Commands"]},{"cell_type":"markdown","id":"jGi9QZlA6_lH","metadata":{"id":"jGi9QZlA6_lH"},"source":["#### access git (via Google Drive)"]},{"cell_type":"code","execution_count":null,"id":"RDGTQvQU6s6R","metadata":{"id":"RDGTQvQU6s6R"},"outputs":[],"source":["repository = 'final'\n","%cd {repository}\n","\n","%ls -a"]},{"cell_type":"markdown","id":"AfBaTkvS7CYE","metadata":{"id":"AfBaTkvS7CYE"},"source":["#### Commit / Status / Push"]},{"cell_type":"code","execution_count":null,"id":"wRoxMllw7LJv","metadata":{"id":"wRoxMllw7LJv"},"outputs":[],"source":["# !git status\n"]},{"cell_type":"code","execution_count":null,"id":"SLH5xYCY7Mw6","metadata":{"id":"SLH5xYCY7Mw6"},"outputs":[],"source":["# !git add ."]},{"cell_type":"code","execution_count":null,"id":"zhBfH31h7Oy8","metadata":{"id":"zhBfH31h7Oy8"},"outputs":[],"source":["# !git config user.email \"michaelmarzec11@gmail.com\"\n","# !git commit -m \"notebook rename\""]},{"cell_type":"code","execution_count":null,"id":"vvcVXbdh7Ta2","metadata":{"id":"vvcVXbdh7Ta2"},"outputs":[],"source":["# !git push"]},{"cell_type":"markdown","id":"8097e241","metadata":{"id":"8097e241"},"source":["## Instructions\n","Cells with a \"Mandatory\" in their title must be run. Cells with a title stating that running is optional do not have to be run."]},{"cell_type":"markdown","id":"994d28a8","metadata":{"id":"994d28a8"},"source":["## Mandatory - Imports\n","\n","Let's start by importing the necessary packages:"]},{"cell_type":"code","execution_count":null,"id":"67130df6","metadata":{"id":"67130df6"},"outputs":[],"source":["!pip install torchmetrics\n","!pip install tfrecord\n","\n","import os.path\n","\n","import torch\n","import torchmetrics\n","import tfrecord\n","import numpy as np\n","from os import walk\n","\n","from torchmetrics import ConfusionMatrix\n","from torchmetrics import F1\n","\n","from torch.utils.data import DataLoader\n","\n","from utils import utils\n","from utils import dataloader\n","from torch import nn\n","from torch import optim\n","\n","# Tqdm progress bar\n","from tqdm import tqdm_notebook"]},{"cell_type":"markdown","id":"fa322bda","metadata":{"id":"fa322bda"},"source":["## Mandatory - Load Training Data\n","\n","Load the training data into memory"]},{"cell_type":"code","execution_count":null,"id":"ec210b89","metadata":{"id":"ec210b89"},"outputs":[],"source":["# Figure out which device this notebook is being run from\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"You are using device: %s\" % device)\n","\n","# Load the training data from memory. Note this training data was created\n","# by converting the tfrecord files from the original dataset\n","training_data = utils.load_pytorch_tensor('./utils/balanced_train_data.pt')\n","training_label = utils.load_pytorch_tensor('./utils/balanced_train_label.pt')\n","\n","# training_data = utils.load_pytorch_tensor('./utils/eval_data.pt')\n","# training_label = utils.load_pytorch_tensor('./utils/eval_label.pt')\n","\n","# make this multi-classification problem a binary classification problem by\n","# selecting all labels which contain a given class and making their label\n","# True, and all others False. In this case, 0 means select the speech class\n","training_label, count = utils.convert_multiclass_to_binary(0, training_label)\n","print(\"Total of \" + str(count) + \" positive examples out of \" + str(training_label.shape[0]) + \" samples\")\n","\n","# convert the training data to floating point\n","training_data = np.float32(training_data)\n","\n","# split the training data into two parts, one for training and the other for validation\n","data_train, label_train, data_val, label_val = \\\n","    utils.split_data_train_val(training_data, training_label, percent_val=0.20)\n","\n","# put on the right device\n","data_train = torch.from_numpy(data_train).to(device)\n","label_train = torch.from_numpy(label_train).to(device)\n","data_val = torch.from_numpy(data_val).to(device)\n","label_val = torch.from_numpy(label_val).to(device)\n","\n","# Load the dataset into an iterable object from which batches can be made\n","train_dataset = dataloader.MusicDataset(data_train, label_train)\n","val_dataset = dataloader.MusicDataset(data_val, label_val)"]},{"cell_type":"markdown","id":"acd6fe0d","metadata":{"id":"acd6fe0d"},"source":["## Optional - Simple Linear Model\n","\n","Let's get a training loop running with this simple linear model, which is nothing but an input, a ReLu, and an output"]},{"cell_type":"code","execution_count":null,"id":"2e3cdbc3","metadata":{"id":"2e3cdbc3"},"outputs":[],"source":["# Linear Model Hyperparameters\n","\n","BATCH_SIZE = 32\n","LEARNING_RATE = 1e-3\n","HIDDEN_LAYER_SIZE = 64\n","NUM_EPOCHS = 50"]},{"cell_type":"code","execution_count":null,"id":"620852e9","metadata":{"id":"620852e9"},"outputs":[],"source":["# Linear Model boilerplate code\n","from models import LinearModel\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","linear_model = LinearModel.LinearModel(10*128, HIDDEN_LAYER_SIZE, 2).to(device)\n","optimizer = optim.Adam(linear_model.parameters(), lr=LEARNING_RATE)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"id":"92288624","metadata":{"id":"92288624"},"outputs":[],"source":["for epoch_idx in range(NUM_EPOCHS):\n","    print(\"-----------------------------------\")\n","    print(\"Epoch %d\" % (epoch_idx+1))\n","    print(\"-----------------------------------\")\n","    \n","    train_loss, avg_train_loss = utils.train(linear_model, train_loader, optimizer, criterion)\n","    scheduler.step(train_loss)\n","\n","    val_loss, avg_val_loss = utils.evaluate(linear_model, val_loader, criterion)\n","\n","    avg_train_loss = avg_train_loss.item()\n","    avg_val_loss = avg_val_loss.item()\n","    print(\"Training Loss: %.4f. Validation Loss: %.4f. \" % (avg_train_loss, avg_val_loss))"]},{"cell_type":"markdown","id":"112c4b3a","metadata":{"id":"112c4b3a"},"source":["## Optional - Simple Convolutional Model\n","\n","Using convolution for sound identification is an established method and has been used on this dataset before. The idea is to make the learnable kernel 1-D and stride it across the sound artifacts. In this simple convolutional model, all 10 seconds of sounds will get flattened into one tensor, and a 1-D kernel strided. "]},{"cell_type":"code","execution_count":null,"id":"7c5af4fb","metadata":{"id":"7c5af4fb"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"id":"44f1ad3e","metadata":{"id":"44f1ad3e"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"id":"8381034a","metadata":{"id":"8381034a"},"outputs":[],"source":["# Simple Convolution Model Hyperparameters\n","\n","BATCH_SIZE = 16\n","LEARNING_RATE = 0.001\n","NUM_EPOCHS = 10\n","\n","START_KERNEL_SIZE = 3\n","DROPOUT_RATE = 0.2\n","\n","\n","# Convolution Boilerplate code\n","from models import SimpleConvolutionModel\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","convolution_model = SimpleConvolutionModel.SimpleConvolutionModel(START_KERNEL_SIZE, DROPOUT_RATE).to(device)\n","optimizer = optim.Adam(convolution_model.parameters(), lr=LEARNING_RATE)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n","criterion = nn.CrossEntropyLoss()\n","\n","\n","for epoch_idx in range(NUM_EPOCHS):\n","    print(\"-----------------------------------\")\n","    print(\"Epoch %d\" % (epoch_idx+1))\n","    print(\"-----------------------------------\")\n","    \n","    train_loss, avg_train_loss = utils.train(convolution_model, train_loader, optimizer, criterion)\n","    scheduler.step(train_loss)\n","\n","    val_loss, avg_val_loss = utils.evaluate(convolution_model, val_loader, criterion)\n","\n","    avg_train_loss = avg_train_loss.item()\n","    avg_val_loss = avg_val_loss.item()\n","    print(\"Training Loss: %.4f. Validation Loss: %.4f. \" % (avg_train_loss, avg_val_loss))"]},{"cell_type":"code","execution_count":null,"id":"839704a5","metadata":{"id":"839704a5"},"outputs":[],"source":["# Convolution 2D Model Hyperparameters\n","\n","BATCH_SIZE = 64\n","LEARNING_RATE = 0.001\n","NUM_EPOCHS = 50\n","\n","START_KERNEL_SIZE = 2\n","DROPOUT_RATE = 0.2\n","\n","\n","# Convolution2D Boilerplate code\n","from models import ConvolutionModel2D\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","convolution_model_2d = ConvolutionModel2D.ConvolutionModel(START_KERNEL_SIZE, DROPOUT_RATE).to(device)\n","optimizer = optim.Adam(convolution_model_2d.parameters(), lr=LEARNING_RATE)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n","\n","weights = torch.tensor([1, 3]).to(device)\n","criterion = nn.BCEWithLogitsLoss(pos_weight=weights)\n","# criterion = nn.CrossEntropyLoss()\n","\n","\n","for epoch_idx in range(NUM_EPOCHS):\n","    print(\"-----------------------------------\")\n","    print(\"Epoch %d\" % (epoch_idx+1))\n","    print(\"-----------------------------------\")\n","    \n","    train_loss, avg_train_loss = utils.train(convolution_model_2d, train_loader, optimizer, criterion)\n","    scheduler.step(train_loss)\n","\n","    val_loss, avg_val_loss = utils.evaluate(convolution_model_2d, val_loader, criterion)\n","\n","    avg_train_loss = avg_train_loss.item()\n","\n","    avg_val_loss = avg_val_loss.item()\n","    print(\"Training Loss: %.4f. Validation Loss: %.4f. \" % (avg_train_loss, avg_val_loss))"]},{"cell_type":"code","execution_count":null,"id":"268d1f34","metadata":{"id":"268d1f34"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"id":"346d41f8","metadata":{"id":"346d41f8"},"outputs":[],"source":["# GT Transformer Model Hyperparameters\n","BATCH_SIZE = 32\n","LEARNING_RATE = 1e-5\n","NUM_EPOCHS = 50\n","\n","# GTT Boilerplate code\n","from models import GtTransformer\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","input_size = 10*128\n","gtt = GtTransformer.GtTransformer(input_size, 2, device).to(device)\n","optimizer = optim.Adam(gtt.parameters(), lr=LEARNING_RATE)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n","weights = torch.tensor([1, 3]).to(device)\n","criterion = nn.BCEWithLogitsLoss(pos_weight=weights)\n","# criterion = nn.CrossEntropyLoss()\n","\n","\n","for epoch_idx in range(NUM_EPOCHS):\n","    print(\"-----------------------------------\")\n","    print(\"Epoch %d\" % (epoch_idx+1))\n","    print(\"-----------------------------------\")\n","    \n","    train_loss, avg_train_loss = utils.train(gtt, train_loader, optimizer, criterion)\n","    scheduler.step(train_loss)\n","\n","    val_loss, avg_val_loss = utils.evaluate(gtt, val_loader, criterion)\n","\n","    avg_train_loss = avg_train_loss.item()\n","    avg_val_loss = avg_val_loss.item()\n","    print(\"Training Loss: %.4f. Validation Loss: %.4f. \" % (avg_train_loss, avg_val_loss))"]},{"cell_type":"markdown","id":"7b93f857","metadata":{"id":"7b93f857"},"source":["## Optional - Model Evaluation\n","\n","Pick a model that was trained above and push the evaluation data through it, and compute the model metrics"]},{"cell_type":"code","execution_count":null,"id":"19c4c941","metadata":{"id":"19c4c941"},"outputs":[],"source":["# First, load the evaluation data\n","eval_data = utils.load_pytorch_tensor('./utils/eval_data.pt')\n","eval_label = utils.load_pytorch_tensor('./utils/eval_label.pt')\n","\n","# make this multi-classification problem a binary classification problem\n","eval_label, count = utils.convert_multiclass_to_binary(0, eval_label)\n","print(\"Total of \" + str(count) + \" positive examples out of \" + str(eval_label.shape[0]) + \" samples\")\n","\n","eval_data = np.float32(eval_data)\n","\n","# device = 'cpu' # the GTT model needs to execute on GPU for some reason I cannot yet explain...\n","# put on the right device - for evaluation, we always run from CPU\n","eval_data = torch.from_numpy(eval_data).to(device)\n","eval_label = torch.from_numpy(eval_label).to(device)\n","\n","# Next, pick the model you want to evaluate\n","# options: linear_model, convolution_model, gtt, convolution_model_2d\n","model = gtt \n","\n","\n","# if model = None\n","# place the model on the CPU as well\n","model = model.to(device)\n","\n","print(eval_data.is_cuda)\n","print(eval_label.is_cuda)\n","\n","\n","# push the eval data through the model\n","eval_dataset = dataloader.MusicDataset(eval_data, eval_label)\n","eval_loader = DataLoader(eval_dataset, batch_size=1024, shuffle=True)\n","\n","\n","# declare the metric keepers\n","conf_mat = ConfusionMatrix(num_classes=2).to(device)\n","f1_score = F1(num_classes=2).to(device)\n","total_accuracy = 0.0\n","\n","total_correct_perc = 0.0\n","total_correct = 0\n","total_wrong_perc = 0.0\n","total_wrong = 0\n","\n","with torch.no_grad():\n","  # Get the progress bar\n","  progress_bar = tqdm_notebook(eval_loader, ascii=True)\n","  for batch_idx, data in enumerate(progress_bar):\n","      input_data = data[0].to(device)\n","      correct_labels = data[1].to(device)\n","\n","      prediction = model(input_data)\n","      prediction = torch.softmax(prediction, dim=1)\n","\n","      preds, indcs = torch.max(prediction, dim=1)\n","\n","      correct_labels = torch.argmax(correct_labels, dim=1)\n","\n","      total_correct_perc += preds[indcs == correct_labels].sum()\n","      total_correct += len(preds[indcs == correct_labels])\n","\n","      total_wrong_perc += preds[indcs != correct_labels].sum()\n","      total_wrong += len(preds[indcs != correct_labels])\n","\n","      conf_mat.update(indcs, correct_labels)\n","      f1_score.update(indcs, correct_labels)\n","      accuracy = torchmetrics.functional.accuracy(indcs, correct_labels)\n","      total_accuracy += accuracy\n","      exit(1)\n","      progress_bar.set_description_str(\n","          \"Batch: %d\" % (batch_idx + 1))\n","\n","# avg_acc, conf_mat, f1_score = utils.evaluate_with_metrics(model, eval_loader)\n","avg_accuracy = total_accuracy / len(eval_loader)\n","avg_correct_perc = total_correct_perc / total_correct\n","avg_wrong_perc = total_wrong_perc / total_wrong\n","final_conf_mat = conf_mat.compute()\n","final_f1_score = f1_score.compute()\n","\n","print(\"Model achieved an average accuracy of %.4f on evaluation data\" % avg_accuracy.item())\n","print(\"Confusion Matrix:\")\n","print(str(final_conf_mat))\n","print(\"F1 Score: %.4f\" % final_f1_score.item())\n","print(\"Average score when answering correctly:   {}\".format(avg_correct_perc))\n","print(\"Average score when answering incorrectly: {}\".format(avg_wrong_perc))\n","print(model)"]},{"cell_type":"code","execution_count":null,"id":"f9e53cf3","metadata":{"id":"f9e53cf3"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"cs7643_final_project.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"}},"nbformat":4,"nbformat_minor":5}